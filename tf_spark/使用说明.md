参考：

- [yahoo/TensorFlowOnSpark](https://github.com/yahoo/TensorFlowOnSpark)
- [基于Hadoop分布式集群YARN模式下的TensorFlowOnSpark平台搭建](http://www.cnblogs.com/heimianshusheng/p/6768019.html)
- [超详细从零记录Hadoop2.7.3完全分布式集群部署过程](http://blog.csdn.net/dream_an/article/details/52946840)
- [GetStarted_YARN安装](http://note.youdao.com/noteshare?id=9ae6faea6fec098a2e6be6d5e12121e3&sub=79606510D055480B9FAA2C685B3D8EB3)
- [Distributed TensorFlow](https://www.tensorflow.org/deploy/distributed)

----------

# TensorflowOnSpark使用
- Xshell连接`124.200.40.0` 再ssh转 `10.0.100.25`


# Train

```
cd /home/install/git/myfloder/Arable
```

## 数据转换，执行以下命令：

```python
spark-submit \
--master yarn \
--deploy-mode cluster \
--queue default \
--num-executors 45 \
--executor-memory 2G \
--driver-memory 12G \
--conf spark.dynamicAllocation.enabled=false \
--conf spark.yarn.maxAppAttempts=1 \
--jars hdfs://xxxx:8020/spark-tensorflow/spark-tensorflow-connector-1.0-SNAPSHOT.jar \
mnist_data_setup.py \
--num-partitions 200 \
--imgPixel 2 \
--channels 3 \
--output hdfs://xxxx:8020/user/root/inference \
--format pickle
```
注：因为数据输出存放到`inference` ，需提前在hdfs新建这个目录，使用命令`hdfs dfs -mkdir inference` 

出现 `final status: SUCCEEDED` 表明运行完成，可以进行下一步。


如果出现错误需调试，打开远程桌面连接`124.200.40.0:33981` ，打开浏览器输入`http://10.0.100.5:8080/#/login`

## 执行训练

```python
spark-submit \
--master yarn \
--deploy-mode cluster \
--queue default \
--num-executors 45 \
--executor-memory 2G \
--driver-memory 12G \
--py-files ../../TensorFlowOnSpark/tfspark.zip,mnist_dist.py \
--conf spark.dynamicAllocation.enabled=false \
--conf spark.yarn.maxAppAttempts=1 \
--conf spark.yarn.executor.memoryOverhead=12288 \
mnist_spark.py \
--images hdfs://xxx:8020/user/root/inference/42/images \
--labels hdfs://xxx:8020/user/root/inference/42/labels \
--format pickle \
--mode train \
--model hdfs://xxxx:8020/user/root/model_arable2 \
--batch_size 50 \
--epochs 1 \
--steps 100 \
--acc 0.8 \
--dropout 0.6 \
--learning_rate 1e-2 \
--model_name model.ckpt 
```

出现 `final status: SUCCEEDED` 表明运行完成，可以进行下一步。


# Inference

```
cd /home/install/git/myfloder/inference
```

## 数据转换

```
spark-submit \
--master yarn \
--deploy-mode cluster \
--queue default \
--num-executors 45 \
--executor-memory 2G \
--driver-memory 12G \
--conf spark.dynamicAllocation.enabled=false \
--conf spark.yarn.maxAppAttempts=1 \
--jars hdfs://xxxx:8020/spark-tensorflow/spark-tensorflow-connector-1.0-SNAPSHOT.jar \
mnist_data_setup.py \
--num-partitions 20 \
--imgPixel 2 \
--channels 3 \
--output hdfs://xxxx:8020/user/root/inference \
--format pickle 
```
## 执行推理

```
spark-submit \
--master yarn \
--deploy-mode cluster \
--queue default \
--num-executors 45 \
--executor-memory 2G \
--driver-memory 12G \
--py-files ../../TensorFlowOnSpark/tfspark.zip,mnist_dist.py \
--conf spark.dynamicAllocation.enabled=false \
--conf spark.yarn.maxAppAttempts=1 \
--conf spark.yarn.executor.memoryOverhead=12288 \
mnist_spark.py  \
--images hdfs://xxxx:8020/user/root/inference/13/images \
--labels hdfs://xxxx:8020/user/root/inference/13/labels \
--format pickle \
--mode inference \
--model hdfs://xxxx:8020/user/root/model_arable2 \
--output predictions
```

> 在`124.200.40.0`上执行  `scp -r <文件夹/文件> root@10.0.100.25:/root` 将`124.200.40.0`上的<文件夹/文件> 复制到 `10.0.100.25:/root`目录下

>  在`124.200.40.0`上执行  `scp -r root@10.0.100.25:/root/<文件夹/文件>` 将`10.0.100.25:/root/`上的<文件夹/文件> 复制到 `124.200.40.0`

- `hdfs dfs -rm -r inference` 删除目录
- `hdfs dfs -ls inference` 查看hdfs上的内容
- `yarn application -kill application_1502181070712_0574`   杀掉进程
- `hdfs dfs -ls inference/|wc -l`   显示多少条
- `hdfs dfs -put  xxx data`  将xxx 上传到 hdfs的data目录
- `hdfs dfs -get xxx ./`   将hdfs的xxx（文件或文件夹）复制到本地
- `spark-submit test.py`  执行脚本 test.py
- 将提交命令写在shell脚本中，执行`sh xx.sh` 来执行命令
- `nohup <command> &` # 后台运行程序
- `ps aux|grep python` # 查看提交的python 任务
- `top` # 监控 cpu使用情况
- `kill -9 任务id` # 杀掉任务

- `vim nohup.out` # 查看输出情况
- `nvidia-smi` 查看GPU使用情况
-  `kill -9 任务id` # 杀掉任务


# Tensorflow分布式使用
使用Xshell连接`124.200.40.0` 再ssh转 `10.0.100.25` 分别打开
14、15、16 （只用3台说明问题）

将`mnist.py` 复制到这几台目录下（如：/root 目录）

## train

- 14 执行：(ps:0)

```
python mnist_dist.py \
--ps_hosts=10.0.100.14:2220 \
--worker_hosts=10.0.100.15:2221,10.0.100.16:2222 \
--job_name="ps" \
--train=1 \
--task_index=0 \
--image_size=400 \
--image_channel=3 \
--epochs=2 \
--batch_size=1 \
--display_step=1 \
--n_class=3 \
--dropout=0.8 \
--model_name="save_net.ckpt" 
```


- 15 执行：(worker:0)

```
python mnist_dist.py \
--ps_hosts=10.0.100.14:2220 \
--worker_hosts=10.0.100.15:2221,10.0.100.16:2222 \
--job_name="worker" \
--train=1 \
--task_index=0 \
--image_size=400 \
--image_channel=3 \
--epochs=2 \
--batch_size=1 \
--display_step=1 \
--n_class=3 \
--dropout=0.8 \
--model_name="save_net.ckpt" 
```
- 16执行（worker:1）

```
python mnist_dist.py \
--ps_hosts=10.0.100.14:2220 \
--worker_hosts=10.0.100.15:2221,10.0.100.16:2222 \
--job_name="worker" \
--train=1 \
--task_index=1 \
--image_size=400 \
--image_channel=3 \
--epochs=2 \
--batch_size=1 \
--display_step=1 \
--n_class=3 \
--dropout=0.8 \
--model_name="save_net.ckpt" 
```

## inference

- 14执行(ps:0)
```
python mnist_dist.py \
--ps_hosts=10.0.100.14:2220 \
--worker_hosts=10.0.100.15:2221,10.0.100.16:2222 \
--job_name="ps" \
--train=-1 \
--task_index=0 \
--start_index=0 \
--end_index=2 \
--image_size=400 \
--image_channel=3 \
--n_class=3 \
--save_image_path="./image_walter/"
```

- 15执行(worker:0)
```
python mnist_dist.py \
--ps_hosts=10.0.100.14:2220 \
--worker_hosts=10.0.100.15:2221,10.0.100.16:2222 \
--job_name="worker" \
--train=-1 \
--task_index=0 \
--start_index=0 \
--end_index=2 \
--image_size=400 \
--image_channel=3 \
--n_class=3 \
--save_image_path="./image_walter/"
```

- 16执行(worker:1)
```
python mnist_dist.py \
--ps_hosts=10.0.100.14:2220 \
--worker_hosts=10.0.100.15:2221,10.0.100.16:2222 \
--job_name="worker" \
--train=-1 \
--task_index=1 \
--start_index=0 \
--end_index=2 \
--image_size=400 \
--image_channel=3 \
--n_class=3 \
--save_image_path="./image_walter/"
```
注：这里使用1个ps，2个worker

如果 14、15、16做ps，17,18,19，20做worker

- 14 需修改成以下参数

```
--ps_hosts=10.0.100.14:2220,10.0.100.15:2221,10.0.100.16:2222
--worker_hosts=10.0.100.17:2223,10.0.100.18:2224,10.0.100.19:2225
--job_name="ps"
--task_index=0
```
- 15 需修改成以下参数

```
--ps_hosts=10.0.100.14:2220,10.0.100.15:2221,10.0.100.16:2222
--worker_hosts=10.0.100.17:2223,10.0.100.18:2224,10.0.100.19:2225
--job_name="ps"
--task_index=1
```
- 16 需修改成以下参数

```
--ps_hosts=10.0.100.14:2220,10.0.100.15:2221,10.0.100.16:2222
--worker_hosts=10.0.100.17:2223,10.0.100.18:2224,10.0.100.19:2225
--job_name="ps"
--task_index=2
```

- 17 需修改成以下参数

```
--ps_hosts=10.0.100.14:2220,10.0.100.15:2221,10.0.100.16:2222
--worker_hosts=10.0.100.17:2223,10.0.100.18:2224,10.0.100.19:2225
--job_name="worker"
--task_index=0
```
- 18 需修改成以下参数

```
--ps_hosts=10.0.100.14:2220,10.0.100.15:2221,10.0.100.16:2222
--worker_hosts=10.0.100.17:2223,10.0.100.18:2224,10.0.100.19:2225
--job_name="worker"
--task_index=1
```
- 19 需修改成以下参数

```
--ps_hosts=10.0.100.14:2220,10.0.100.15:2221,10.0.100.16:2222
--worker_hosts=10.0.100.17:2223,10.0.100.18:2224,10.0.100.19:2225
--job_name="worker"
--task_index=2
```
