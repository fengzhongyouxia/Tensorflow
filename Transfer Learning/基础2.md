# 1、model训练
```python
from tensorflow.examples.tutorials.mnist import input_data
import tensorflow as tf
import numpy as np

mnist = input_data.read_data_sets("MNIST_data/", one_hot=True)
w = 28
h = 28
c = 1

x = tf.placeholder(tf.float32, shape=[None, h*w*c], name='input')
y_ = tf.placeholder(tf.float32, shape=[None,10], name='y_')

w1=tf.Variable(tf.truncated_normal([h*w*c,128], dtype=tf.float32, stddev=0.1)*0.001, name="w1")
b1=tf.Variable(tf.constant(0.1, dtype=tf.float32, shape=[128]), name="b1")

w2=tf.Variable(tf.truncated_normal([128,10], dtype=tf.float32, stddev=0.1)*0.001, name="w2")
b2=tf.Variable(tf.constant(0.1, dtype=tf.float32, shape=[10]), name="b2")

layer1=tf.nn.relu(tf.matmul(x,w1)+b1)
y=tf.matmul(layer1,w2)+b2

cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y, labels=y_))
optimize = tf.train.AdamOptimizer(learning_rate=1e-1).minimize(cost)
correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

init = tf.global_variables_initializer()

saver=tf.train.Saver()
with tf.Session() as sess:
    sess.run(init)
    # 验证之前是否已经保存了检查点文件
    ckpt = tf.train.get_checkpoint_state('./output/')
    if ckpt and ckpt.model_checkpoint_path:
        saver.restore(sess, ckpt.model_checkpoint_path)

    for epoch_index in range(2):
        for i in range(1000):
            batch_xs, batch_ys = mnist.train.next_batch(128)
            feed={
                x: batch_xs,
                y_: batch_ys}
            sess.run([optimize], feed_dict=feed)
            if i%100==0:
                print('step',i,'acc',sess.run(accuracy,feed),'loss',sess.run(cost,feed))

            # saver.save(sess,'./output/model.ckpt',global_step=i)
            saver.save(sess, './output/model.ckpt')
```
# 2、提取模型
## 1、第一层冻结权重参数，第二层使用随机权重初始化

```python
from tensorflow.examples.tutorials.mnist import input_data
import tensorflow as tf
import numpy as np

mnist = input_data.read_data_sets("MNIST_data/", one_hot=True)
w = 28
h = 28
c = 1

x = tf.placeholder(tf.float32, shape=[None, h*w*c], name='input')
y_ = tf.placeholder(tf.float32, shape=[None,10], name='y_')

w1=tf.Variable(tf.truncated_normal([h*w*c,128], dtype=tf.float32, stddev=0.1)*0.001, name="w1",trainable=False)
b1=tf.Variable(tf.constant(0.1, dtype=tf.float32, shape=[128]), name="b1",trainable=False) # trainable=False 参数不更新

w2=tf.Variable(tf.truncated_normal([128,10], dtype=tf.float32, stddev=0.1)*0.001, name="w2")
b2=tf.Variable(tf.constant(0.1, dtype=tf.float32, shape=[10]), name="b2")

layer1=tf.nn.relu(tf.matmul(x,w1)+b1)
y=tf.matmul(layer1,w2)+b2

cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y, labels=y_))
optimize = tf.train.AdamOptimizer(learning_rate=1e-1).minimize(cost)
correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

init = tf.global_variables_initializer()

saver=tf.train.Saver([w1,b1])
# 或
'''
saver=tf.train.Saver([tf.variable_op_scope(w1,name_or_scope='w1:0').args[0],
                      tf.variable_op_scope(b1, name_or_scope='b1:0').args[0]])
'''

with tf.Session() as sess:
    sess.run(init)
    # 验证之前是否已经保存了检查点文件
    ckpt = tf.train.get_checkpoint_state('./output/')
    if ckpt and ckpt.model_checkpoint_path:
        saver.restore(sess, ckpt.model_checkpoint_path)

    for epoch_index in range(2):
        for i in range(1000):
            batch_xs, batch_ys = mnist.train.next_batch(128)
            feed={
                x: batch_xs,
                y_: batch_ys}
            sess.run([optimize], feed_dict=feed)
            if i%100==0:
                print('step',i,'acc',sess.run(accuracy,feed),'loss',sess.run(cost,feed))

            # saver.save(sess,'./output/model.ckpt',global_step=i)
            # saver.save(sess, './output/model.ckpt')

```
## 2、第一层冻结权重参数，第二层使用模型提取的权重初始化

```
from tensorflow.examples.tutorials.mnist import input_data
import tensorflow as tf
import numpy as np

mnist = input_data.read_data_sets("MNIST_data/", one_hot=True)
w = 28
h = 28
c = 1

x = tf.placeholder(tf.float32, shape=[None, h*w*c], name='input')
y_ = tf.placeholder(tf.float32, shape=[None,10], name='y_')

w1=tf.Variable(tf.truncated_normal([h*w*c,128], dtype=tf.float32, stddev=0.1)*0.001, name="w1",trainable=False)
b1=tf.Variable(tf.constant(0.1, dtype=tf.float32, shape=[128]), name="b1",trainable=False) # trainable=False 参数不更新

w2=tf.Variable(tf.truncated_normal([128,10], dtype=tf.float32, stddev=0.1)*0.001, name="w2")
b2=tf.Variable(tf.constant(0.1, dtype=tf.float32, shape=[10]), name="b2")

layer1=tf.nn.relu(tf.matmul(x,w1)+b1)
y=tf.matmul(layer1,w2)+b2

cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y, labels=y_))
optimize = tf.train.AdamOptimizer(learning_rate=1e-1).minimize(cost)
correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

init = tf.global_variables_initializer()

saver=tf.train.Saver() # 默认是提取所有变量
'''
# 或
saver=tf.train.Saver([tf.variable_op_scope(w1,name_or_scope='w1:0').args[0],
                      tf.variable_op_scope(b1, name_or_scope='b1:0').args[0],
                      tf.variable_op_scope(w2, name_or_scope='w2:0').args[0],
                      tf.variable_op_scope(b2, name_or_scope='b2:0').args[0]])
'''
with tf.Session() as sess:
    sess.run(init)
    # 验证之前是否已经保存了检查点文件
    ckpt = tf.train.get_checkpoint_state('./output/')
    if ckpt and ckpt.model_checkpoint_path:
        saver.restore(sess, ckpt.model_checkpoint_path)

    for epoch_index in range(2):
        for i in range(1000):
            batch_xs, batch_ys = mnist.train.next_batch(128)
            feed={
                x: batch_xs,
                y_: batch_ys}
            sess.run([optimize], feed_dict=feed)
            if i%100==0:
                print('step',i,'acc',sess.run(accuracy,feed),'loss',sess.run(cost,feed))

            # saver.save(sess,'./output/model.ckpt',global_step=i)
            # saver.save(sess, './output/model.ckpt')
```

## 3、使用pywrap_tensorflow提取模型参数
参考：http://blog.csdn.net/wc781708249/article/details/78040735

```python
# -*- coding:utf-8 -*-

from tensorflow.examples.tutorials.mnist import input_data
import tensorflow as tf
import numpy as np
from tensorflow.python import pywrap_tensorflow

mnist = input_data.read_data_sets("MNIST_data/", one_hot=True)
w = 28
h = 28
c = 1

logdir='./output/'
ckpt = tf.train.get_checkpoint_state(logdir)
reader = pywrap_tensorflow.NewCheckpointReader(ckpt.model_checkpoint_path)
# var_to_shape_map = reader.get_variable_to_shape_map()
# reader.get_tensor(key)

x = tf.placeholder(tf.float32, shape=[None, h*w*c], name='input')
y_ = tf.placeholder(tf.float32, shape=[None,10], name='y_')

# w1=tf.Variable(tf.truncated_normal([h*w*c,128], dtype=tf.float32, stddev=0.1)*0.001, name="w1",trainable=False)
# b1=tf.Variable(tf.constant(0.1, dtype=tf.float32, shape=[128]), name="b1",trainable=False) # trainable=False 参数不更新

w1=tf.Variable(reader.get_tensor('w1'),trainable=False,name="w1")
b1=tf.Variable(reader.get_tensor('b1'),trainable=False,name="b1")

w2=tf.Variable(tf.truncated_normal([128,10], dtype=tf.float32, stddev=0.1)*0.001, name="w2")
b2=tf.Variable(tf.constant(0.1, dtype=tf.float32, shape=[10]), name="b2")

layer1=tf.nn.relu(tf.matmul(x,w1)+b1)
y=tf.matmul(layer1,w2)+b2

cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y, labels=y_))
optimize = tf.train.AdamOptimizer(learning_rate=1e-1).minimize(cost)
correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

init = tf.global_variables_initializer()

saver=tf.train.Saver([tf.variable_op_scope(w2, name_or_scope='w2:0').args[0],
                      tf.variable_op_scope(b2, name_or_scope='b2:0').args[0]])
with tf.Session() as sess:
    sess.run(init)
    # 验证之前是否已经保存了检查点文件
    ckpt = tf.train.get_checkpoint_state(logdir)
    if ckpt and ckpt.model_checkpoint_path:
        saver.restore(sess, ckpt.model_checkpoint_path)

    for epoch_index in range(2):
        for i in range(1000):
            batch_xs, batch_ys = mnist.train.next_batch(128)
            feed={
                x: batch_xs,
                y_: batch_ys}
            sess.run([optimize], feed_dict=feed)
            if i%100==0:
                print('step',i,'acc',sess.run(accuracy,feed),'loss',sess.run(cost,feed))

            # saver.save(sess,'./output/model.ckpt',global_step=i)
            # saver.save(sess, './output/model.ckpt')
```

## 4、先提取所有层参数，然后单独对输出层的参数重新初始化

```python
# -*- coding:utf-8 -*-

from tensorflow.examples.tutorials.mnist import input_data
import tensorflow as tf
import numpy as np
from tensorflow.python import pywrap_tensorflow

mnist = input_data.read_data_sets("MNIST_data/", one_hot=True)
w = 28
h = 28
c = 1

logdir='./output/'

x = tf.placeholder(tf.float32, shape=[None, h*w*c], name='input')
y_ = tf.placeholder(tf.float32, shape=[None,10], name='y_')

w1=tf.Variable(tf.truncated_normal([h*w*c,128], dtype=tf.float32, stddev=0.1)*0.001, name="w1",trainable=False)
b1=tf.Variable(tf.constant(0.1, dtype=tf.float32, shape=[128]), name="b1",trainable=False) # trainable=False 参数不更新

w2=tf.Variable(tf.truncated_normal([128,10], dtype=tf.float32, stddev=0.1)*0.001, name="w2")
b2=tf.Variable(tf.constant(0.1, dtype=tf.float32, shape=[10]), name="b2")

layer1=tf.nn.relu(tf.matmul(x,w1)+b1)
y=tf.matmul(layer1,w2)+b2

cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y, labels=y_))
optimize = tf.train.AdamOptimizer(learning_rate=1e-1).minimize(cost)
correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

init = tf.global_variables_initializer()
init2=tf.initialize_variables([w2,b2])

saver=tf.train.Saver() # 提取所有变量参数，包括输出层参数
with tf.Session() as sess:
    sess.run(init)
    # 验证之前是否已经保存了检查点文件
    ckpt = tf.train.get_checkpoint_state(logdir)
    if ckpt and ckpt.model_checkpoint_path:
        saver.restore(sess, ckpt.model_checkpoint_path)
    sess.run(init2) # 初始化输出层的参数

    for epoch_index in range(2):
        for i in range(1000):
            batch_xs, batch_ys = mnist.train.next_batch(128)
            feed={
                x: batch_xs,
                y_: batch_ys}
            sess.run([optimize], feed_dict=feed)
            if i%100==0:
                print('step',i,'acc',sess.run(accuracy,feed),'loss',sess.run(cost,feed))

            # saver.save(sess,'./output/model.ckpt',global_step=i)
            # saver.save(sess, './output/model.ckpt')
```
## 5、增加一层，第一层使用提取的参数，其他层重新初始化

```Python
# -*- coding:utf-8 -*-

from tensorflow.examples.tutorials.mnist import input_data
import tensorflow as tf
import numpy as np
from tensorflow.python import pywrap_tensorflow

mnist = input_data.read_data_sets("MNIST_data/", one_hot=True)
w = 28
h = 28
c = 1

logdir='./output/'

x = tf.placeholder(tf.float32, shape=[None, h*w*c], name='input')
y_ = tf.placeholder(tf.float32, shape=[None,10], name='y_')

w1=tf.Variable(tf.truncated_normal([h*w*c,128], dtype=tf.float32, stddev=0.1)*0.001, name="w1",trainable=False)
b1=tf.Variable(tf.constant(0.1, dtype=tf.float32, shape=[128]), name="b1",trainable=False) # trainable=False 参数不更新

w2=tf.Variable(tf.truncated_normal([128,256], dtype=tf.float32, stddev=0.1)*0.001, name="w2")
b2=tf.Variable(tf.constant(0.1, dtype=tf.float32, shape=[256]), name="b2")

w3=tf.Variable(tf.truncated_normal([256,10], dtype=tf.float32, stddev=0.1)*0.001, name="w3")
b3=tf.Variable(tf.constant(0.1, dtype=tf.float32, shape=[10]), name="b3")

layer1=tf.nn.relu(tf.matmul(x,w1)+b1)
layer2=tf.nn.relu(tf.matmul(layer1,w2)+b2)
y=tf.matmul(layer2,w3)+b3

cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y, labels=y_))
optimize = tf.train.AdamOptimizer(learning_rate=1e-1).minimize(cost)
correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

init = tf.global_variables_initializer()
init2=tf.initialize_variables([w2,b2,w3,b3])

saver=tf.train.Saver([w1,b1]) # 只提取第一层参数
with tf.Session() as sess:
    sess.run(init)
    # 验证之前是否已经保存了检查点文件
    ckpt = tf.train.get_checkpoint_state(logdir)
    if ckpt and ckpt.model_checkpoint_path:
        saver.restore(sess, ckpt.model_checkpoint_path)
    sess.run(init2) # 初始化输出层的参数

    for epoch_index in range(2):
        for i in range(1000):
            batch_xs, batch_ys = mnist.train.next_batch(128)
            feed={
                x: batch_xs,
                y_: batch_ys}
            sess.run([optimize], feed_dict=feed)
            if i%100==0:
                print('step',i,'acc',sess.run(accuracy,feed),'loss',sess.run(cost,feed))

            # saver.save(sess,'./output/model.ckpt',global_step=i)
            # saver.save(sess, './output/model.ckpt')
```
